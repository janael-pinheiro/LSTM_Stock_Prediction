# -*- coding: utf-8 -*-
"""LSTMStockPricePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13kgcBkR_R7V-Dw6jVA48SQIIfui6ETn4

Install the investpy library. This library will be used to get stock hystorical data.
"""

!pip3 install -q investpy

"""Import the necessary libraries."""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dropout

import numpy as np

from sklearn.preprocessing import MinMaxScaler

import investpy

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

from datetime import date

"""Defines the country in which company shares are available."""

country="united states"

"""Determine the period for historical data."""

years = 5

initial_date = "{0}/{1}/{2}".format(date.today().day, date.today().month, date.today().year-years)

final_date = date.today().strftime("%d/%m/%Y")

"""Ticket of some of the most popular US stocks:


*   Google: GOOGL;
*   Apple: AAPL;
*   Amazon: AMZN;
*   Facebook: FB;
*   Tesla: TSLA;
*   Berkshire Hathaway: BRKa.
"""

stock_name = "TSLA"

stock_prices = investpy.get_stock_historical_data(stock_name, country=country, from_date=initial_date, to_date=final_date)

stock_prices

historical_data = stock_prices["Close"].values

plt.plot(historical_data)
plt.xlabel("Day")
plt.ylabel("Price (US$)")
plt.xlim(0,1261)
plt.grid(True)
plt.tight_layout()

scaler = MinMaxScaler(feature_range = (0, 1))

def createModel(X_train, nUnits, hiddenLayers):
    model = Sequential()
    model.add(LSTM(units = nUnits, return_sequences = True, input_shape = (X_train.shape[1], 1)))
    model.add(Dropout(0.2))
    for h in range(hiddenLayers):
        model.add(LSTM(units = nUnits, return_sequences = True))
        model.add(Dropout(0.2))
    model.add(LSTM(units = nUnits))
    model.add(Dropout(0.2))
    model.add(Dense(units = 1))
    model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=["mse"])
    return model

"""20 days."""

window = 20

threshold = len(historical_data)-20

train_data = historical_data[:threshold]

test_data = historical_data[threshold:]

train_data = scaler.fit_transform(train_data.reshape(-1,1))

train_data

X_train = []
y_train = []

X_test = []
y_test = []

for i in range(window, threshold):
    X_train.append(train_data[i-window:i, 0])
    y_train.append(train_data[i, 0])

len(X_train)

test_data.shape

X_train, y_train = np.array(X_train), np.array(y_train)

X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

test_data = historical_data[threshold-window:].reshape(-1,1)

test_data.shape

test_data = scaler.fit_transform(test_data)

test_data.shape

len(test_data)

for x in range(window, len(test_data)):
    X_test.append(test_data[x-window:x,0])

X_test = np.array(X_test)

X_test

X_test.shape

X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

X_test.shape

"""Creates the model."""

regressor = createModel(X_train, 150, 4)

"""Train the model."""

regressor.fit(X_train, y_train, epochs = 60, batch_size = 10)

"""After several tests, I found that the values for number of epochs, batch_size, number of neurons and hidden layers, interesting are 10, 60, 150 and 4, respectively. Clearly, other values for these hyper parameters can achieve better performance.

Save the model.
"""

regressor.save("{0}_stock_price_regressor.h5".format(stock_name))

predictions = regressor.predict(X_test)

predictions_inverse = scaler.inverse_transform(predictions)

plt.plot(historical_data[threshold:], color = 'red', label = 'Historical prices for {0}.'.format(stock_name))
plt.plot(predictions_inverse, color = 'blue', label = 'Predicted prices for {0}.'.format(stock_name))
plt.legend()
plt.xlabel("Days")
plt.ylabel("Price (US$)")
plt.grid(True)